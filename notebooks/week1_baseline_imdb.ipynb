{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN14MNTMqUKiGcv++eih9mf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkshatTalwar/cs175-teamx-sentiment/blob/main/notebooks/week1_baseline_imdb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B14tCVRcHUs4"
      },
      "outputs": [],
      "source": [
        "!pip -q install scikit-learn pandas numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import tarfile\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "SUR5BUVyJsXk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = Path(\"data\")\n",
        "data_folder.mkdir(exist_ok=True)\n",
        "\n",
        "dataset_url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "dataset_file = data_folder / \"aclImdb_v1.tar.gz\""
      ],
      "metadata": {
        "id": "AHNox5VnLtJw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(dataset_url, dataset_file)\n",
        "print(\"Downloaded:\", dataset_file)"
      ],
      "metadata": {
        "id": "SaIiFSFeLyAw",
        "outputId": "ce1ebb45-2b97-4c95-f63e-c70b80f4ec8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: data/aclImdb_v1.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tarfile.open(dataset_file, \"r:gz\") as tar:\n",
        "    tar.extractall(path=data_folder)\n",
        "\n",
        "print(\"Dataset extracted\")"
      ],
      "metadata": {
        "id": "njCcnc-7L0PK",
        "outputId": "c7096169-5068-4b0f-d46f-3d0012c2e8a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-422107889.py:2: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(path=data_folder)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_folder = data_folder / \"aclImdb\"\n",
        "\n",
        "print(\"Dataset folder exists:\", imdb_folder.exists())\n",
        "print(\"Train folder:\", (imdb_folder / \"train\").exists())\n",
        "print(\"Test folder:\", (imdb_folder / \"test\").exists())\n"
      ],
      "metadata": {
        "id": "K0W0HXuJL5fW",
        "outputId": "0c311cda-ecf0-4323-801d-eeb45f92388f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset folder exists: True\n",
            "Train folder: True\n",
            "Test folder: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data test loading test\n",
        "sample_file = imdb_folder / \"train\" / \"pos\"\n",
        "files = list(sample_file.glob(\"*.txt\"))\n",
        "text = files[0].read_text(encoding=\"utf-8\")\n",
        "print(text[:500])"
      ],
      "metadata": {
        "id": "mXpBTa7lMFGx",
        "outputId": "84981973-34ed-4436-b334-429396fe1f8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I enjoyed this movie. Haven't seen Andy Griffith in ages and felt he fit this role perfectly. I've associated him with comedy but am pleased to see that he's versatile.<br /><br />I wasn't troubled that Dotty's \"anxiety disorder\" may not have been verbatim from a psychiatric textbook. There are zillions of whatever-phobias and neuroses, and these can take on a broad variety of quantitative and qualitative forms. She is clearly a sensitive with extra-sensory powers as was understood by the local \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "labels = []\n",
        "\n",
        "#positive reviews\n",
        "pos_folder = imdb_folder / \"train\" / \"pos\"\n",
        "for file in pos_folder.glob(\"*.txt\"):\n",
        "    texts.append(file.read_text(encoding=\"utf-8\"))\n",
        "    labels.append(1)\n",
        "\n",
        "#negative reviews\n",
        "neg_folder = imdb_folder / \"train\" / \"neg\"\n",
        "for file in neg_folder.glob(\"*.txt\"):\n",
        "    texts.append(file.read_text(encoding=\"utf-8\"))\n",
        "    labels.append(0)\n",
        "\n",
        "print(\"Total reviews loaded:\", len(texts))\n",
        "print(\"Positive reviews:\", labels.count(1))\n",
        "print(\"Negative reviews:\", labels.count(0))"
      ],
      "metadata": {
        "id": "AqPQqkO5MSA0",
        "outputId": "ff7a7b9d-a93a-401d-9d57-123c17295ea1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total reviews loaded: 25000\n",
            "Positive reviews: 12500\n",
            "Negative reviews: 12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    texts, labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(X_train))\n",
        "print(\"Val size:\", len(X_val))\n"
      ],
      "metadata": {
        "id": "0G2ZR7GZMmu6",
        "outputId": "0e7468a2-0c23-44bf-e99e-7102d0c00ca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 20000\n",
            "Val size: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=50000)\n",
        "\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_val_vec = vectorizer.transform(X_val)\n",
        "\n",
        "print(\"Vector shape (train):\", X_train_vec.shape)\n",
        "print(\"Vector shape (val):\", X_val_vec.shape)\n"
      ],
      "metadata": {
        "id": "EQRmb6uTMyhL",
        "outputId": "67ff32d9-b727-4b8c-a3f1-292252f3448f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector shape (train): (20000, 50000)\n",
            "Vector shape (val): (5000, 50000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "pred = model.predict(X_val_vec)\n",
        "\n",
        "acc = accuracy_score(y_val, pred)\n",
        "f1 = f1_score(y_val, pred)\n",
        "\n",
        "print(\"Validation Accuracy:\", acc)\n",
        "print(\"Validation F1:\", f1)\n"
      ],
      "metadata": {
        "id": "wHl39qe4M4S8",
        "outputId": "71463d90-f4bb-439c-fa3e-f9a568f5547e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.879\n",
            "Validation F1: 0.8809758016919143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts = []\n",
        "test_labels = []\n",
        "\n",
        "pos_folder_test = imdb_folder / \"test\" / \"pos\"\n",
        "for file in pos_folder_test.glob(\"*.txt\"):\n",
        "    test_texts.append(file.read_text(encoding=\"utf-8\"))\n",
        "    test_labels.append(1)\n",
        "\n",
        "neg_folder_test = imdb_folder / \"test\" / \"neg\"\n",
        "for file in neg_folder_test.glob(\"*.txt\"):\n",
        "    test_texts.append(file.read_text(encoding=\"utf-8\"))\n",
        "    test_labels.append(0)\n",
        "\n",
        "print(\"Test reviews loaded:\", len(test_texts))\n",
        "print(\"Test positives:\", test_labels.count(1))\n",
        "print(\"Test negatives:\", test_labels.count(0))"
      ],
      "metadata": {
        "id": "Tvs3njrhM9e6",
        "outputId": "2ec4fe12-5ee3-4fc1-ae84-54be6f3a6260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test reviews loaded: 25000\n",
            "Test positives: 12500\n",
            "Test negatives: 12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "vectorizer2 = TfidfVectorizer(stop_words=\"english\", max_features=50000)\n",
        "\n",
        "X_train_full = vectorizer2.fit_transform(texts)\n",
        "X_test_full = vectorizer2.transform(test_texts)\n",
        "\n",
        "model2 = LogisticRegression(max_iter=1000)\n",
        "model2.fit(X_train_full, labels)\n",
        "\n",
        "test_pred = model2.predict(X_test_full)\n",
        "\n",
        "test_acc = accuracy_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred)\n",
        "\n",
        "print(\"TEST Accuracy:\", test_acc)\n",
        "print(\"TEST F1:\", test_f1)\n"
      ],
      "metadata": {
        "id": "QwLF931vOe4i",
        "outputId": "e55c3f1a-bd74-4dda-8d5b-f1d1cd6886a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST Accuracy: 0.879\n",
            "TEST F1: 0.8790822240876204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gradio\n"
      ],
      "metadata": {
        "id": "oVuMHeLvOjCZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "# 1) Train baseline model (TF-IDF + Logistic Regression)\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=50000)\n",
        "\n",
        "X_train_vec = vectorizer.fit_transform(texts)\n",
        "\n",
        "baseline_model = LogisticRegression(max_iter=1000)\n",
        "baseline_model.fit(X_train_vec, labels)\n",
        "\n",
        "\n",
        "# 2) Test on official test set\n",
        "X_test_vec = vectorizer.transform(test_texts)\n",
        "\n",
        "test_probs = baseline_model.predict_proba(X_test_vec)[:, 1]   # P(positive)\n",
        "test_pred = (test_probs >= 0.5).astype(int)\n",
        "\n",
        "test_acc = accuracy_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred)\n",
        "\n",
        "print(\"Baseline TEST accuracy:\", test_acc)\n",
        "print(\"Baseline TEST F1:\", test_f1)\n",
        "\n",
        "\n",
        "# 3) Predict one review (used by the UI)\n",
        "def predict_one_review(text, threshold=0.8):\n",
        "    x = vectorizer.transform([text])\n",
        "    p_pos = float(baseline_model.predict_proba(x)[0, 1])\n",
        "\n",
        "    pred = 1 if p_pos >= 0.5 else 0\n",
        "    label = \"POSITIVE\" if pred == 1 else \"NEGATIVE\"\n",
        "\n",
        "    confidence = p_pos if pred == 1 else (1 - p_pos)\n",
        "\n",
        "    if confidence < threshold:\n",
        "        label = \"UNCERTAIN\"\n",
        "\n",
        "    return {\n",
        "        \"prediction\": label,\n",
        "        \"p_positive\": round(p_pos, 4),\n",
        "        \"confidence\": round(confidence, 4),\n",
        "        \"threshold\": threshold\n",
        "    }\n",
        "\n",
        "\n",
        "# 4) Correct ECE (calibration score)\n",
        "def compute_ece_correct(probs_pos, true_labels, bins=10):\n",
        "    probs_pos = np.array(probs_pos)\n",
        "    true_labels = np.array(true_labels)\n",
        "\n",
        "    pred = (probs_pos >= 0.5).astype(int)\n",
        "    conf = np.where(pred == 1, probs_pos, 1 - probs_pos)\n",
        "    correct = (pred == true_labels).astype(int)\n",
        "\n",
        "    edges = np.linspace(0, 1, bins + 1)\n",
        "    ece = 0.0\n",
        "\n",
        "    for i in range(bins):\n",
        "        lo, hi = edges[i], edges[i+1]\n",
        "        mask = (conf >= lo) & (conf < hi) if i < bins-1 else (conf >= lo) & (conf <= hi)\n",
        "\n",
        "        if mask.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        avg_conf = conf[mask].mean()\n",
        "        avg_acc = correct[mask].mean()\n",
        "        ece += (mask.mean()) * abs(avg_acc - avg_conf)\n",
        "\n",
        "    return float(ece)\n",
        "\n",
        "baseline_ece = compute_ece_correct(test_probs, test_labels, bins=10)\n",
        "print(\"Baseline ECE (correct):\", baseline_ece)\n",
        "\n",
        "\n",
        "# 5) Get some wrong examples (used by the UI)\n",
        "def get_error_examples(k=10):\n",
        "    wrong = [i for i in range(len(test_labels)) if test_pred[i] != test_labels[i]]\n",
        "    if len(wrong) == 0:\n",
        "        return []\n",
        "\n",
        "    chosen = random.sample(wrong, min(k, len(wrong)))\n",
        "    examples = []\n",
        "\n",
        "    for idx in chosen:\n",
        "        examples.append({\n",
        "            \"true_label\": \"POSITIVE\" if test_labels[idx] == 1 else \"NEGATIVE\",\n",
        "            \"predicted_label\": \"POSITIVE\" if test_pred[idx] == 1 else \"NEGATIVE\",\n",
        "            \"p_positive\": round(float(test_probs[idx]), 4),\n",
        "            \"text\": test_texts[idx][:600]\n",
        "        })\n",
        "\n",
        "    return examples\n"
      ],
      "metadata": {
        "id": "VqqOoROfdDO5",
        "outputId": "722b0b3c-52a0-41be-8eaa-4bf3b4b36797",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline TEST accuracy: 0.879\n",
            "Baseline TEST F1: 0.8790822240876204\n",
            "Baseline ECE (correct): 0.09539715753787606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def ui_predict(text, threshold, model_name):\n",
        "    if model_name == \"Baseline (TF-IDF + Logistic Regression)\":\n",
        "        return predict_one_review(text, threshold=threshold)\n",
        "    else:\n",
        "        return {\"prediction\": \"Coming soon\", \"p_positive\": None, \"confidence\": None, \"threshold\": threshold}\n",
        "\n",
        "def ui_show_calibration(model_name):\n",
        "    if model_name == \"Baseline (TF-IDF + Logistic Regression)\":\n",
        "        return {\n",
        "            \"model\": model_name,\n",
        "            \"ece\": round(float(baseline_ece), 4),\n",
        "            \"test_accuracy\": round(float(test_acc), 4),\n",
        "            \"test_f1\": round(float(test_f1), 4)\n",
        "        }\n",
        "    else:\n",
        "        return {\"model\": model_name, \"ece\": None, \"note\": \"Coming soon\"}\n",
        "\n",
        "def ui_show_errors(model_name, k):\n",
        "    if model_name == \"Baseline (TF-IDF + Logistic Regression)\":\n",
        "        return get_error_examples(k=int(k))\n",
        "    else:\n",
        "        return [{\"note\": \"Coming soon\"}]\n",
        "\n",
        "with gr.Blocks(title=\"CS175 Sentiment + Confidence Tool\") as demo:\n",
        "    gr.Markdown(\"# CS175 Sentiment + Confidence Tool\")\n",
        "    gr.Markdown(\"Paste a review, get prediction + confidence, and explore calibration + common mistakes.\")\n",
        "\n",
        "    model_name = gr.Dropdown(\n",
        "        [\"Baseline (TF-IDF + Logistic Regression)\", \"DistilBERT (coming soon)\"],\n",
        "        value=\"Baseline (TF-IDF + Logistic Regression)\",\n",
        "        label=\"Model\"\n",
        "    )\n",
        "\n",
        "    with gr.Tab(\"Predict\"):\n",
        "        text_in = gr.Textbox(lines=8, label=\"Review text\")\n",
        "        threshold = gr.Slider(0.50, 0.95, value=0.80, step=0.01, label=\"High-confidence threshold\")\n",
        "        btn = gr.Button(\"Predict\")\n",
        "        pred_out = gr.JSON(label=\"Output\")\n",
        "        btn.click(ui_predict, inputs=[text_in, threshold, model_name], outputs=pred_out)\n",
        "\n",
        "    with gr.Tab(\"Calibration\"):\n",
        "        cal_btn = gr.Button(\"Show calibration stats\")\n",
        "        cal_out = gr.JSON(label=\"Calibration + Test Results\")\n",
        "        cal_btn.click(ui_show_calibration, inputs=model_name, outputs=cal_out)\n",
        "\n",
        "    with gr.Tab(\"Error examples\"):\n",
        "        k = gr.Slider(5, 30, value=10, step=1, label=\"How many wrong examples to show\")\n",
        "        err_btn = gr.Button(\"Show misclassified examples\")\n",
        "        err_out = gr.JSON(label=\"Misclassified Examples\")\n",
        "        err_btn.click(ui_show_errors, inputs=[model_name, k], outputs=err_out)\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "id": "4wJJQryXdlkX",
        "outputId": "1e64c9da-36ac-4962-965c-040b2f625e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0181618aface991a6c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0181618aface991a6c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JJ-z6dIcgTZd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}